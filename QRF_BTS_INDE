############################################
# MODELE QRF - APPROCHE BOOTSTRAP ##########
# BERAMBADI - INDE #########################
# FAVIERE MARYLINE - STAGE UMR LISAH #######
# 2024 #####################################
############################################

################
# PREPARATION ##
################

rm(list=ls())
graphics.off()

# LIBRAIRIES #
library(pls) 
library(raster)       
library(rgdal)      
library(caret)
library(e1071)
library(ade4)         
library(gstat)
library(quantregForest)
library(snow)
library(mlr)
library(tibble)
library(tuneRanger)
library(randomForest)
library(rasterVis)
library(sf)
data(SAGA_pal)


################
#   ENTREES    #
################

# ENREGISTREMENT HEURE SYSTEME AU DEBUT EXECUTION # 
temps_debut <- Sys.time()

# INITIALISATION DE LA VARIABLE QUI EMPILERA LES CARTES MLR EN FONCTION DU NOMBRE ITERATION # 
FinalMap <- stack() 

# INITIALISATION DE LA VARIABLE QUI EMPILERA LES CARTES QRF EN FONCTION DU NOMBRE ITERATION # 
FinalmapQRF <- stack()

# INITIALISATION DE LA LISTE DES ERREURS MLR # 
metrics_list <- list() 
result <- list()  # Liste pour stocker les résultats
resultTest <- list()
# TROUVER LES DONNEES S-2 #
pathS2="C:/Users/maryf/Documents/code/1_Data/"
#pathS2="//147.99.18.48/shared-data/Maryline_Faviere/Data_Inde/1_Data/"

# TROUVER LES MESURES #
path="C:/Users/maryf/Documents/code/1_Data/"  
#path="//147.99.18.48/shared-data/Maryline_Faviere/Data_Inde/1_Data/"

# CHEMIN DE SORTIE #
#pathResults="Y:/Maryline_Faviere/Résultats/MLR/Inde_20170424/"
pathResults="C:/Users/maryf/Documents/code/data_versailles/test/"

# CREATION DU STACK POUR LES PREDICTIONS # 
stackQRF <- stack()
stack05 <- stack()
stack95 <- stack()
PICP <- list()

#pathResults="//147.99.18.48/shared-data/Maryline_Faviere/res/"

# DISTANCE DE MAHALANOBIS #
seuilMD=3.5 

# DATE IMAGE S2 #
DateImage="20170424"

Property="Clay"
prop_unite="g.kg-1"

# VALEUR MAX DES PLOTS #
LimMaxscatterplot=80 

R2_values <- c()
RMSE_values <- c()
bias_values <- c()
RPD_values <- c()
RPIQ_values <- c()
PICP_values <- c()

R2T_values <- c()
RMSET_values <- c()
biasT_values <- c()
RPDT_values <- c()
RPIQT_values <- c()
PICPT_values <- c()

# OUVRIR LES ECHANTILLONS ET PROPRIETES DE SOL #
PropSoil_NBSS<-read.table(paste(path,"164_3Prop_BM_AOBO.csv",sep=""), row.names=1,head=T) # LECTURE DU .CSV #
dim(PropSoil_NBSS) # AFFICHAGE DES DIMENSIONS (LIGNES ET COLONNES) #
head(PropSoil_NBSS)# AFFICHAGE DES PREMIERES LIGNES DU TABLEAU #
str(PropSoil_NBSS) # AFFICHAGE DE LA STRUCTURE DE L'OBJET #

# EXTRACTION DE LA COLONNE PROPERTY #
Prop=PropSoil_NBSS[Property]

# CONVERSION DES DONNEES EN DONNEES SPATIALES #
coordinates(PropSoil_NBSS) <- c("X_UTM_WGS84_43N","Y_UTM_WGS84_43N")
coord <- coordinates(PropSoil_NBSS)

SavePerfo=matrix(c(0.0),1,14) # CREATION DE LA MATRICE POUR STOCKER LES PERFORMANCES DU MODELE # 
SavePerfo=as.data.frame(SavePerfo) # CONVERSION DE LA MATRICE EN DATAFRAME # 
colnames(SavePerfo)=c("nbrData", "nbrOutlier","R2cal","RMSEcal","R2val","RMSEval","RPDval","RPIQval","Biasval", "R2Test", "RMSETest", "RPDTest", "RPIQTest", "BiasTest") # ATTRIBUTION DE NOMS AUX COLONNES # 

# OUVERTURE DE SE #
setwd(pathS2) # DEFINIR LE REPERTOIRE ACTUEL #
NameImage=c(paste("bareSoil_S2_",DateImage,sep="")) # CREATION VECTEUR POUR CONTENIR DE NOM DE IMAGE CONCATENE "BARESOIL_S2_" #
rownames(SavePerfo)=paste(DateImage) # AFFECTION DU NOM ET DATE SPECIFIE COMME NOM DE LIGNE DANS SAVEPERFO # 

namefile=paste(NameImage,".tif",sep="") # CONCATENATION DU NOM DE FICHIER #
S2 = readGDAL(paste(pathS2,namefile, sep = "")) # LECTURE DES IMAGES RASTER AVEC LA FONCTION READGDAL() # 
S2Band.bare=stack(S2) # EMPILEMENT DE BANDES AVEC LA FONCTION STACK() #

S3 = raster(paste(pathS2,namefile, sep = "")) # LECTURE DES IMAGES RASTER AVEC LA FONCTION RASTER() #
SS3Band.bare=stack(S3) # EMPILEMENT DE BANDES A PARTIR DE S3 # 


################################
#   PREPARATION DES DONNEES    #
################################

# EXTRACTION DES DONNEES DES PILES DE RASTER # 
Spectres=extract(S2Band.bare, PropSoil_NBSS) # EXTRACTION DES VALEURS SPECTRALES DES PIXELS DE IMAGE DES POINTS DE SOL DANS PROPSOIL_NBSS # 
Argile_spectres=data.frame(Spectres) # CREATION DATAFRAME A PARTIR DES VALEURS SPECTRALES EXTRAITES STOCKEE DANS LA VARIABLE PROP #

Argile_spectres$Prop=Prop # AJOUTE UNE COLONNE PROP AU DATAFRAME CONTENANT DES VALEURS DE PROPRIETES DU SOL DE LA VARIABLE PROP # 
Argile_spectres$coord=coord # AJOUTE UNE COLONN COORD AU DATAFRAME CONTENANT LES COORDONNEES XY DES ECHANTILLONS # 

# REORGANISATION DES COLONNES POUR QUE LES PROPRIETES DU SOL SOIENT LA PREMIERE COLONNE ECT # 
Argile_spectresTemp=Argile_spectres 
Argile_spectresTemp[,1]=Argile_spectres[,11]
Argile_spectresTemp[,2:11]=Argile_spectres[,1:10]

colnames(Argile_spectresTemp)[1]=Property
colnames(Argile_spectresTemp)[2:11]=colnames(Argile_spectres)[1:10]
rownames(Argile_spectresTemp)=rownames(Prop)

Argile_spectres=Argile_spectresTemp

# CONVERTIR LES NOMS DES ECHANTILLONS EN VALEUR # 
Argile_spectres <- rownames_to_column(Argile_spectres, var = "ID")

# AFFICHAGE DES DIMENSIONS DU DATAFRAME ET AFFICHAGE DES PREMIERES LIGNES # 
print(dim(Argile_spectres))
head(Argile_spectres)


###################################
#   SUPPRESSION DES DONNEES NA    #
###################################

spectresFalseTrue<-is.na(Spectres) # CREATION DE LA MATRICE OU CHAQUE ELEMENT EST TRUE SI LA VALEUR DES SPECTRES EST NA, ET FALSE SINON # 
l=1    # INITIALISATION DU COMPTEUR A 1 # 
Argile_spectres_SansNA=Argile_spectres    # CREATION COPIE DE SAUVEGARDE DU DATAFRAME # 

# BOUCLE QUI PARCOURT CHAQUE LIGNE DE PROP #
# SI LA VALEUR DE SELECT EST FALSE, ALORS LIGNE EST COPIEE DANS BDBERAMBADISANSNAN A POSITION l, ET INCRIMENTATION DE 1 # 
for (i in 1:dim(Prop)[1]) {
  if (spectresFalseTrue[i,1]==FALSE) {
    Argile_spectres_SansNA[l,]<-Argile_spectres[i,]
    l=l+1  
  }
}

# LES LIGNES NA SONT SUPPRIME EN PRENANT QUE LES LIGNES JUSQUA POSITION l-1. 
Argile_spectres_SansNA=Argile_spectres_SansNA[2:l-1,]
head(Argile_spectres_SansNA)

# Définir les noms des échantillons comme noms de lignes
rownames(Argile_spectres_SansNA) <- Argile_spectres_SansNA$ID



################################
#   PREPARATION DES DONNEES    #
################################

# EXTRACTION DES DONNEES DES PILES DE RASTER # 
Spectres=extract(S2Band.bare, PropSoil_NBSS) # EXTRACTION DES VALEURS SPECTRALES DES PIXELS DE IMAGE DES POINTS DE SOL DANS PROPSOIL_NBSS # 
Argile_spectres=data.frame(Spectres) # CREATION DATAFRAME A PARTIR DES VALEURS SPECTRALES EXTRAITES STOCKEE DANS LA VARIABLE PROP #

Argile_spectres$Prop=Prop # AJOUTE UNE COLONNE PROP AU DATAFRAME CONTENANT DES VALEURS DE PROPRIETES DU SOL DE LA VARIABLE PROP # 
Argile_spectres$coord=coord # AJOUTE UNE COLONN COORD AU DATAFRAME CONTENANT LES COORDONNEES XY DES ECHANTILLONS # 

# REORGANISATION DES COLONNES POUR QUE LES PROPRIETES DU SOL SOIENT LA PREMIERE COLONNE ECT # 
Argile_spectresTemp=Argile_spectres 
Argile_spectresTemp[,1]=Argile_spectres[,11]
Argile_spectresTemp[,2:11]=Argile_spectres[,1:10]

colnames(Argile_spectresTemp)[1]=Property
colnames(Argile_spectresTemp)[2:11]=colnames(Argile_spectres)[1:10]
rownames(Argile_spectresTemp)=rownames(Prop)

Argile_spectres=Argile_spectresTemp

# CONVERTIR LES NOMS DES ECHANTILLONS EN VALEUR # 
Argile_spectres <- rownames_to_column(Argile_spectres, var = "ID")

# AFFICHAGE DES DIMENSIONS DU DATAFRAME ET AFFICHAGE DES PREMIERES LIGNES # 
print(dim(Argile_spectres))
head(Argile_spectres)


##############################################
#   SUPPRESSION DES DONNEES DE VEGETATION    #
##############################################
spectresFalseTrue<-is.na(Spectres) # CREATION DE LA MATRICE OU CHAQUE ELEMENT EST TRUE SI LA VALEUR DES SPECTRES EST NA, ET FALSE SINON # 
l=1    # INITIALISATION DU COMPTEUR A 1 # 
Argile_spectres_SansNA=Argile_spectres    # CREATION COPIE DE SAUVEGARDE DU DATAFRAME # 

# BOUCLE QUI PARCOURT CHAQUE LIGNE DE PROP #
# SI LA VALEUR DE SELECT EST FALSE, ALORS LIGNE EST COPIEE DANS BDBERAMBADISANSNAN A POSITION l, ET INCRIMENTATION DE 1 # 
for (i in 1:dim(Prop)[1]) {
  if (spectresFalseTrue[i,1]==FALSE) {
    Argile_spectres_SansNA[l,]<-Argile_spectres[i,]
    l=l+1  
  }
}

# LES LIGNES NA SONT SUPPRIME EN PRENANT QUE LES LIGNES JUSQUA POSITION l-1. 
Argile_spectres_SansNA=Argile_spectres_SansNA[2:l-1,]
head(Argile_spectres_SansNA)

# Définir les noms des échantillons comme noms de lignes
rownames(Argile_spectres_SansNA) <- Argile_spectres_SansNA$ID


########################################
#   PREPARATION DES DONNEES DE TEST    #
########################################

nb_total_samples <- dim(Argile_spectres_SansNA)[1] # DETERMINATION DU NOMBRE TOTAL ECHANTILLONS SOL #
SavePerfo[1] <- nb_total_samples # SAUVEGARDE DU NOMBRE ECHANTILLONS # 
matrice_clay_sorted <- Argile_spectres_SansNA[order(Argile_spectres_SansNA[, "Clay"]),, drop = FALSE] # TRI DES VALEURS ARGILES EN ORDRE CROISSANT # 
selected_values <- matrix(nrow = 0, ncol = ncol(matrice_clay_sorted)) # INITIALISATION DE LA MATRICE POUR STOCJER LES VALEURS SELECTIONNEES # 

# SELECTTION DES VALEURS TOUTES LES 7 VALEURS PAR ORDRE CROISSANT # 
for (i in seq(7, nb_total_samples, by = 7)) {
  selected_values <- rbind(selected_values, matrice_clay_sorted[i, ])
}

# Définir les noms des échantillons comme noms de lignes
rownames(selected_values) <- selected_values$ID

selected_values=t(selected_values) # INVERSEMENT DES LIGNES ET COLONNES #
selected_values=t(selected_values) # INVERSEMENT DES LIGNES ET COLONNES #

ExtractNameTest <-as.matrix(selected_values[,1]) # EXTRACTION NOMS DE LIGNE 1 # 
selected_values <- selected_values[, -1]

# Appliquer as.numeric à chaque élément de la matrice
selected_values <- apply(selected_values, c(1, 2), as.numeric)

# Reconvertir la matrice en caractères
selected_values <- as.matrix(selected_values)

selected_indices <- seq(7, nb_total_samples, by = 7) # INDICES DE LIGNES NON SELECTIONNEES POUR DATA TEST # 
non_selected_indices <- setdiff(seq(nb_total_samples), selected_indices) # DIFFERENCE ENTRE LE TOTAL ET INDICES NON SELECTIONNES #
non_selected_values <- matrice_clay_sorted[non_selected_indices, ] # RECUPERATION DES VALEURS DE LIGNE ENTIERE # 
rownames(non_selected_values) <- non_selected_values$ID
non_selected_values=t(non_selected_values) # INVERSEMENT DES LIGNES ET COLONNES #
non_selected_values=t(non_selected_values) # INVERSEMENT DES LIGNES ET COLONNES #

non_selected_values <- non_selected_values[, -1]
# Appliquer as.numeric à chaque élément de la matrice
non_selected_values <- apply(non_selected_values, c(1, 2), as.numeric)

# Reconvertir la matrice en caractères
non_selected_values <- as.matrix(non_selected_values)

ExtractProp_Test<-as.matrix(selected_values[,1]) # ETRACTION DES PROPRIETE DU SOL DE LA 1ERE LIGNE DE BDBERAMBADISANSNAN ET CONVERSION DANS MATRICE # 
ExtractProp_Test=t(ExtractProp_Test)
ExtractSPectres_Test<-as.matrix(selected_values[,2:11]) # EXTRACTIONS SPETRES DES LIGNES 2 A 11 DE BDBERAMBADISANSNAN # 

VTEST <- as.data.frame(ExtractSPectres_Test) # CREATION DATAFRAME # 
SpectACPyTest<-t(scale(VTEST, center = FALSE, scale = FALSE)) # CENTRAGE DES VALEURS SPECTRO # 
SpectACPyTest=t(SpectACPyTest)

#ExtractProp_Test=t(ExtractProp_Test) # INVERSEMENT DES LIGNES ET COLONNES #
ProprieteSolTest<-ExtractProp_Test[1,] # CONVERSION EN NUMERIQUE # 
DataTest<-data.frame(cbind(ProprieteSolTest, SpectACPyTest)) # FUSION DES PROPRIETES SOL ET SPECTRO # 
colnames(DataTest)[1] <- "ProprieteSol"

########################################
#   PREPARATION DE TEST / TRAIN DB    #
#######################################

non_selected_values=t(non_selected_values) # INVERSEMENT DES LIGNES ET COLONNES #

ExtractProp_CALVAL<-as.matrix(non_selected_values[1,]) # ETRACTION DES PROPRIETE DU SOL DE LA 1ERE LIGNE ET CONVERSION DANS MATRICE # 
ExtractSPectres_CALVAL<-as.matrix(non_selected_values[2:11,]) # EXTRACTIONS SPETRES DES LIGNES 2 A 11 # 
ExtractSPectres_CALVAL=t(ExtractSPectres_CALVAL)
non_selected_values=t(non_selected_values) # INVERSEMENT DES LIGNES ET COLONNES #

# CALCUL DU NOMBRE DE DONNEES DE VALIDATION ET DE CALIBRATION # 
(NbrDataValid <- trunc(dim(non_selected_values)[1]/4))   # NOMBRE DE DONNEES DE VALIDATION EST CALCULE EN DIVISANT PAR 4 LE NOMBRE TOT DE COLONNES #         
(NbrDataCalib <- dim(non_selected_values)[1] - NbrDataValid) # NOMBRE DE DONNEES DE CALIBRATION EST CALCULE COMME LA DIFF ENTRE LE NOMBRE TOT DE COLONNES ET NBR DE DONNEES DE VALIDATION # 
NbrDataTest <- dim(selected_values)[1] # NOMBRE DE DONNEES TEST #

# SAUVEGARDE DES ECHANTILLONS TEST #
write.csv(selected_values, file = paste0(pathResults, "MLR__Points_Test.csv"), row.names = FALSE)


# DEPART DE LA BOUCLE #
iteration <- 100
resultMetrics <- vector("list", length = iteration)
resultMetricsTest <- vector("list", length = iteration)

# LE NOMBRE ITERATIONS VOULUES # 
while (iteration > 0) {
  num <- iteration   # INDICATION DU NUMERO DE LA BOUCLE ACTUELLE DANS CERTAINES DONNEES EN SORTIE # 
  
  tirages_CALVAL <- sample(dim(non_selected_values)[1]) # TIRAGE ALEATOIRE DES DONNEES CAL / VAL # 
  
  non_selected_values=t(non_selected_values) # INVERSEMENT DES LIGNES ET COLONNES #
  
  # INITIALISATION DES ENSEMBLES DE DONNEES DE CALIBRATION ET DE VALIDATION # 
  # Réinitialiser la matrice SpectreBerambadiCalib
  SpectreBerambadiCalib <- NULL
  
  SpectreBerambadiCalib <- non_selected_values[, tirages_CALVAL[1:NbrDataCalib]]
  SpectreBerambadiValid <- non_selected_values[, tirages_CALVAL[(NbrDataCalib + 1):length(tirages_CALVAL)]]
  non_selected_values=t(non_selected_values)
  # EXTRCATION DES DONNEES SPECTRALES DE CALIB DE LA MATRICE # 
  SpectMOdifCalib <- SpectreBerambadiCalib[2:11,]      # CHAQUE LIGNE REPRESENTE UN ECHANTILLON ET CHAQUE COLONNE UNE LONGUEUR ONDE OU BANDE SPECTRALE # 
  
  # CONVERSION DE LA MATRICE SPECTMODIFCALIB EN OABJET DE TYPE DATAFRAME (VCAL) 
  vCAL <- as.data.frame(SpectMOdifCalib)
  
  # SAUVEGARDE DES POINTS DE CALIBRATION EN CSV # 
  SpectreBerambadiCalib=t(SpectreBerambadiCalib)
  write.csv(SpectreBerambadiCalib, file = paste0(pathResults, "MLR_", num, "Points_Calibration.csv"), row.names = FALSE)
  
  #####################################
  #   RECHERCHE OUTLIERS SPECTRAUX    #
  #####################################
  # ANALYSE EN COMPOSANTES PRINCIPALES (PCA) SUR LES DONNEES SPECTRALES [VCAL] 
  dudinir <- dudi.pca(t(vCAL),center = TRUE, scale=TRUE,scannf = F) # DUDI.PCA PREND EN ENTREE UNE MATRICE DE DONNEES OU LES COLONNES REPRESENTENT LES VARIABLES ET LES LIGNES DES OBSERVATIONS #
  
  # CALCUL DU % DE VARIANCE EXPLIQUEE  (PVE) POUR CHAQUE COMPOSANTE PRINCIPALE DE PCA # 
  pve <- 100 * dudinir$eig/sum(dudinir$eig) # DUDINIR$EIG CONTIENT LES VALEURS PROPRES DES COMPOSANTES PRINCIPALES # 
  
  # DETERMINATION DU NBR DE COMPOSANTES ACP # 
  out<-as.double(0)  # INITIALISE UNE VARIABLE OUT A 0 POUR CALCULER LE POURCENTAGE TOT DE LA VARIANCE EXPLIQUEE # 
  nf<-0   # INITALISE LE NBR DE COMPOSANTES A 0 # 
  for (i in 1:100){  # BOUCLE SUR LES COMPOSANTES PRINCIPALES POUR CALCULER LE NBR DE COMPOSANTES NECESSAIRES POUR EXPLIQUER 100% DE LA VARIANCE # 
    out<-as.double(out) + as.double(pve)[i]  # AJOUTE LE PVE DE CHAQUE COMPOSANTE A OUT # 
    nf<-nf+1   # INCREMENTE LE NBR DE COMPOSANTES # 
  }
  out # AFFICHE LE % TOT DE VARIANCE EXPLIQUEE # 
  nf  # AFFICHE LE NBR DE COMPOSANTES NECESSAIRES POUR EXPLIQUER 100% DE LA VARIANCE # 
  
  nf<-3  # FIXE LE NBR DE COMPOSANTES A UTILSER POUR ANALYSE A 3 # 
  
  # ANCIEN CALCUL DE LA DISTANCE DE MAHALANOBIS # 
  S <-  cov(dudinir$tab[,1:nf])  # CALCULE LA MATRICE DE COVARIANCE DES COMPOSANTES PRINCIPALES SELECTIONNEES # 
  det(S)  # CALCULE LE DETERMINANT DE LA MATRICE DE COVARIANCE S # 
  D2<-sqrt(mahalanobis(dudinir$tab[,1:nf],colMeans(dudinir$tab[,1:nf]) , S))   # CALCULE LA DISTANCE DE MAHALANOBIS POUR CHAQUE OBSERVATION / CENTRE DE DISTRIBUTION DES COMPOSANTES PRINCIPALES # 
  
  # CALCULE DU NBR OUTLIERS SPECTRAUX # 
  nbroutlier<-as.double(0) # INITIALISE LE NBR OUTLIERS A 0 # 
  NumEchant<-as.double(0)  # INITALISE UN VECTEUR POUR STOCKER LES INDICES DES OUTLIERS # 
  NoMOutlier<-as.double(0)  # INITIALISE UN VECTEUR POUR STOCKER LES NOMS DES OUTLIERS # 
  for (i in 1:dim(vCAL)[2]){   # BOUCLE SUR CHAQUE OBSERVATION POUR IDENTIFIER LES OUTLIERS # 
    if (as.double(D2)[i] > seuilMD)  {   # VERIFICATION SI LA DM DEPASSE LE SEUIL DEFINI # 
      nbroutlier<-nbroutlier+1     # INCREMENTATION DU NBR OUTLIERS # 
      NumEchant[nbroutlier]<-i  # STOCKAGE INDICE OUTLIERS # 
      NoMOutlier[nbroutlier]<-rownames(SpectMOdifCalib)[i]   # STOCKAGE DU NOM DE OUTLIERS # 
      D2[i]<-NA   # MARQUE LA DM DE OUTLIERS COMME NA POUR EXCLURE DE ANALYSE # 
    }
  }
  
  select<-is.na(D2)  # CREATION VECTEUR BOOLEENS POUR SELECTIONNNER OBSERVATIONS QUI NE SONT PAS OUTLIERS # 
  SpectreBerambadiCalib=t(SpectreBerambadiCalib)
  
  SpectreBerambadiCalib2<-SpectreBerambadiCalib[,!select]  
  
  nbroutlier  # AFFICHAGE DU NBR TOT DES OUTLIERS # 
  NumEchant  # AFFICHAGE DES INDICES DES OUTLIERS # 
  D2[NumEchant]  # AFFICHAGE DES DM DES OUTLIERS # 
  
  SavePerfo[2]=nbroutlier  # STOCKAGE DU NBR OUTLIERS IDENTIFIES DANS SAVEPERFO[2] # 
  
  vCAL2<-vCAL[!select]  # FILTRE DES DONNEES DE VCAL EN FONCTION DU VECTEUR SELECT #
  SpectACP<-t(scale(vCAL2, center = FALSE, scale = FALSE)) # CENTRE ET MET A ECHELLE DONNEES DANS VCAL2 # 
  
  NbrDataCalib2<-dim(vCAL2)[2] # CALCULE LE NBR DE VARIABLES DANS VCAL2 EN ACCEDANT A LA DIMENSION 2 DE LA MATRICE VACL2 # 
  
  # MISE DES MESURES ARGILES DANS LE VECTEUR PROPRIETESOL # 
  ProprieteSolCalib<-SpectreBerambadiCalib2[1,]  # EXTRACTION DES MESURES DE PROPRIETES DU SOL DE SPECTREBERAMBADICALIB2 ET LES ASSIGE A VARIABLE PROPRIETESOLCALIB # 
  
  DataCalib<-data.frame(cbind(ProprieteSolCalib, SpectACP)) # CREATION DATAFRAME EN COMBINANT LES MESURES DE LA PROPRIETE D SOL ET DONNEES SPECTRALES MISES A ECHELLE # 
  colnames(DataCalib)[1]=c("ProprieteSol") # RENOMMAGE DE LA 1ERE COLONNE DE DATACALIB EN PROPRIETESOL # 
  #rownames(selected_values) <- selected_values$ID
  
  
  ##############################################
  #   PREPARATION DES DONNEES DE VALIDATION    #
  ##############################################
  
  # EXTRACTION DES VARIABLES NIR DE LA MATRIICE SPECTREBERAMBADIVALID EN EXCLUANT LA 1ERE LIGNE DES PROP DU SOL #
  SpectMOdifValid<-(SpectreBerambadiValid[2:11,])     
  
  vVAL<-as.data.frame(SpectMOdifValid) # CONVERSION DE LA MATRICE SPECTMODIFVALID EN DATARAME NOMME VVAL # 
  SpectACPy<-t(scale(vVAL, center = FALSE, scale = FALSE)) # CENTRE ET MET A ECHELLE DONNEES NIR DANS VVAL #  
  
  ProprieteSolValid<-SpectreBerambadiValid[1,] # EXTRACTION DES MESIRES DE LA PROP DU SOL DE LA 1ERE LIGNE DE MATRICE SPECTREBERAMBADIVALID ET LES ASSIGNE A LA VARIABLE PROPRIEESOLVALID # 
  
  DataValid<-data.frame(cbind(ProprieteSolValid, SpectACPy)) # CREATION DU DATAFRAME DATAVALID EN COMBINANT LES MESURES DE PROP DU SOL ET DONNEES NIR MISES A ECHELLE # 
  colnames(DataValid)=colnames(DataCalib) # LES NOMS DES COLONNES DE DATAVALID CORRESPONDENT A CEUX DE DATACALIB #
  
  setwd(pathResults) # DEFINITION DE EMPLACEMENT SORTIE #
  tiff(filename = paste(pathResults, "/", "MLR", "_", num, "_", Property, "_", DateImage, "_Distribution_Values.tiff", sep = ""), width = 2000, height = 2000, units = "px", bg = "white", res = 300) 
  
  selected_values=t(selected_values)
  
  # DIFFERENTE DONNEES DE HISTOGRAMME ET COULEUR # 
  hist(SpectreBerambadiCalib[1,], col = "red")
  hist(SpectreBerambadiValid[1,], add = TRUE, col = "blue")
  hist(selected_values[1,], add = TRUE, col = "green")
  
  # DONNEES EN ENTREE HISTOGRAMME # 
  NbTrain <- dim(SpectreBerambadiCalib)[2]
  NbTest <- dim(SpectreBerambadiValid)[2]
  NbT <- dim(selected_values)[2]
  
  legend("topright", c(paste(NbTrain, " Données de calibration"), paste(NbTest, " Données de validation"), paste(NbT, "Données de test")), fill = c("red", "blue", "green"))
  dev.off()
  
  # SAUVEGARDE DES POINTS DE CALIBRATION EN CSV # 
  SpectreBerambadiValid=t(SpectreBerambadiValid)
  write.csv(SpectreBerambadiValid, file = paste0(pathResults, "MLR_", num, "Points_Vaidation.csv"), row.names = FALSE)


############################################
##### PREPARATION DES DONNEES DU QRF  ######
############################################

# Retirer les deux dernières colonnes de non_selected_values
Argile_spectresQRF <- non_selected_values[, -(ncol(non_selected_values)-1):-(ncol(non_selected_values))]

# EXTRATION ET REDFINITION DES NOMS DES COLONNES # 
target <- "ProprieteSol"       # LA PROPRIETE DE SOL A PREDIRE # 
Argile_spectresQRF <- as.data.frame(cbind(Argile_spectresQRF[,1], Argile_spectresQRF[,2:11]))
names(Argile_spectresQRF) <- c(target, paste0("band", 1:10)) # ASSIGNER LES NOMS DES COLONNES # 
names(DataCalib) <- c(target, paste0("band", 1:10))

# CREATION DE LA TACHE DE REGRESSION #
clay.task <- makeRegrTask(data = Argile_spectresQRF, target = target)
param <- tuneRanger(clay.task, num.trees = 20, iters = 20, save.file.path = NULL, parameters = list(replace = TRUE))


################
##### QRF ######
################

# Données d'entraînement (bootstrap sample)
calib <- DataCalib

# Données de validation (les données non sélectionnées dans l'échantillon bootstrap)
valid <- DataValid
row_namesVal <- rownames(valid)
valid$id <- row_namesVal
valid_id <- valid[,12]

test <- DataTest
row_namesTest <- rownames(test)
test$id <- row_namesTest
test_id <- test[,12]

# Ajuster mtry si nécessaire
mtry <- min(param$recommended.pars$mtry, ncol(calib) - 1)

# Entrainement du modèle sur les données d'entraînement
mymodel <- ranger(
  data = calib, 
  dependent.variable.name = target, 
  importance = 'permutation', 
  mtry = mtry, 
  min.node.size = param$recommended.pars$min.node.size, 
  sample.fraction = param$recommended.pars$sample.fraction, 
  num.trees = 100, 
  keep.inbag = TRUE, 
  quantreg = TRUE
)

# Prédiction sur les données de validation
prediction <- predict(mymodel, valid, type = 'quantiles', quantiles = c(0.05, 0.5, 0.95))$predictions
predictionTest <- predict(mymodel, DataTest, type = 'quantiles', quantiles = c(0.05, 0.5, 0.95))$predictions

# Construction du résultat
res <- cbind(valid_id, valid[, target], prediction)
resTest <- cbind(test_id, test[, target], predictionTest)


### VALIDATION ###

# Ajout du résultat à la liste de résultats
res <- as.data.frame(res)
resTest <- as.data.frame(resTest)
names(res) <- c('Id', "obs", "pred05", "pred50", "pred95")
names(resTest) <- c('Id', "obs", "pred05", "pred50", "pred95")
result[[iteration]] <- res
resultTest[[iteration]] <- resTest

res$obs <- as.numeric(res$obs)
res$pred50 <- as.numeric(res$pred50)
residualsR <- res$obs - res$pred50
R2 <- 1 - sum(residualsR^2) / sum((res$obs - mean(res$obs))^2)
RMSE <- sqrt(mean(residualsR^2))
RPD <- sd(res$obs) / RMSE
interquartile_range <- quantile(res$obs, 0.75) - quantile(res$obs, 0.25)
RPIQ <- as.numeric(interquartile_range) / RMSE
bias <- mean(residualsR)

result[[iteration]]$cond90 <- ifelse(result[[iteration]]$obs <= result[[iteration]]$pred95 & result[[iteration]]$obs >= result[[iteration]]$pred05, 1, 0)
resultTest[[iteration]]$cond90 <- ifelse(resultTest[[iteration]]$obs <= resultTest[[iteration]]$pred95 & resultTest[[iteration]]$obs >= resultTest[[iteration]]$pred05, 1, 0)

PICP <- round(100 * sum(result[[iteration]]$cond90) / nrow(result[[iteration]]), 2)
PICPT <- round(100 * sum(resultTest[[iteration]]$cond90) / nrow(resultTest[[iteration]]), 2)

### TEST ###

resTest$obs <- as.numeric(resTest$obs)
resTest$pred50 <- as.numeric(resTest$pred50)
residualsRT <- resTest$obs - resTest$pred50
R2T <- 1 - sum(residualsRT^2) / sum((resTest$obs - mean(resTest$obs))^2)
RMSET <- sqrt(mean(residualsRT^2))
RPDT <- sd(resTest$obs) / RMSET
interquartile_rangeT <- quantile(resTest$obs, 0.75) - quantile(resTest$obs, 0.25)
RPIQT <- as.numeric(interquartile_rangeT) / RMSET
biasT <- mean(residualsRT)

result[[iteration]]$cond90 <- ifelse(result[[iteration]]$obs <= result[[iteration]]$pred95 & result[[iteration]]$obs >= result[[iteration]]$pred05, 1, 0)
resultTest[[iteration]]$cond90 <- ifelse(resultTest[[iteration]]$obs <= resultTest[[iteration]]$pred95 & resultTest[[iteration]]$obs >= resultTest[[iteration]]$pred05, 1, 0)

PICP <- round(100 * sum(result[[iteration]]$cond90) / nrow(result[[iteration]]), 2)
PICPT <- round(100 * sum(resultTest[[iteration]]$cond90) / nrow(resultTest[[iteration]]), 2)

# Prédictions sur le raster stack
S2Band_df <- as.data.frame(S2Band.bare, xy = TRUE)
prediction_data <- S2Band_df[, -c(1, 2)]
prediction_data_complete <- na.omit(prediction_data)

pred_S2Band <- predict(mymodel, data = prediction_data_complete, type = 'quantiles', quantiles = c(0.05, 0.5, 0.95))$predictions
S2Band_df$pred <- NA
S2Band_df$pred05 <- NA
S2Band_df$pred50 <- NA
S2Band_df$pred95 <- NA
S2Band_df$pred[complete.cases(prediction_data)] <- pred_S2Band[, 2]  # Prédiction principale
S2Band_df$pred05[complete.cases(prediction_data)] <- pred_S2Band[, 1]  # Quantile 0.05
S2Band_df$pred50[complete.cases(prediction_data)] <- pred_S2Band[, 2]  # Quantile 0.5
S2Band_df$pred95[complete.cases(prediction_data)] <- pred_S2Band[, 3]  # Quantile 0.95

pred_raster <- rasterFromXYZ(S2Band_df[, c("x", "y", "pred")])
pred_raster05 <- rasterFromXYZ(S2Band_df[, c("x", "y", "pred05")])
pred_raster95 <- rasterFromXYZ(S2Band_df[, c("x", "y", "pred95")])

stackQRF <- stack(stackQRF, pred_raster)
stack05 <- stack(stack05, pred_raster05)
stack95 <- stack(stack95, pred_raster95)

# Enregistrement des valeurs dans les listes correspondantes
R2_values <- c(R2_values, R2)
RMSE_values <- c(RMSE_values, RMSE)
bias_values <- c(bias_values, bias)
RPD_values <- c(RPD_values, RPD)
RPIQ_values <- c(RPIQ_values, RPIQ)
PICP_values <- c(PICP_values, PICP)

R2T_values <- c(R2T_values, R2T)
RMSET_values <- c(RMSET_values, RMSET)
biasT_values <- c(biasT_values, biasT)
RPDT_values <- c(RPDT_values, RPDT)
RPIQT_values <- c(RPIQT_values, RPIQT)
PICPT_values <- c(PICPT_values, PICPT)

iteration <- (iteration - 1)  #  FIN DE LA BOUCLE #
} # SORTIE DE LA BOUCLE LORSQUE LA VARIABLE "ITERATION" ATTEINT 0 # 


FinalMap <- stack("C:/Users/maryf/Documents/CARTES_STAGES/BERAMBADI/BOOTSTRAP/QRF/QRF_stack.tif")


quantiles_5 <- calc(FinalMap, fun = function(x) quantile(x, probs = 0.05, na.rm = TRUE))
quantiles_95 <- calc(FinalMap, fun = function(x) quantile(x, probs = 0.95, na.rm = TRUE))

pred_interval_raster_MLR <- quantiles_95 - quantiles_5
writeRaster(pred_interval_raster_MLR, filename = "intervalle_predictionQRF.tif", format = "GTiff", overwrite = TRUE)


# Calcul des moyennes et des écarts-types pour chaque métrique
mean_R2 <- mean(R2_values)
sd_R2 <- sd(R2_values)

mean_RMSE <- mean(RMSE_values)
sd_RMSE <- sd(RMSE_values)

mean_bias <- mean(bias_values)
sd_bias <- sd(bias_values)

mean_RPD <- mean(RPD_values)
sd_RPD <- sd(RPD_values)

mean_RPIQ <- mean(RPIQ_values)
sd_RPIQ <- sd(RPIQ_values)

mean_PICP <- mean(PICP_values)
sd_PICP <- sd(PICP_values)


mean_R2T <- mean(R2T_values)
sd_R2T <- sd(R2T_values)

mean_RMSET <- mean(RMSET_values)
sd_RMSET <- sd(RMSET_values)

mean_biasT <- mean(biasT_values)
sd_biasT <- sd(biasT_values)

mean_RPDT <- mean(RPDT_values)
sd_RPDT <- sd(RPDT_values)

mean_RPIQT <- mean(RPIQT_values)
sd_RPIQT <- sd(RPIQT_values)

mean_PICPT <- mean(PICPT_values)
sd_PICPT <- sd(PICPT_values)


# Créer un data frame avec les résultats
resultsstatsVAL <- data.frame(
  Metric = c("R2", "RMSE", "Bias", "RPD", "RPIQ", "PICP"),
  Mean = c(mean_R2, mean_RMSE, mean_bias, mean_RPD, mean_RPIQ, mean_PICP),
  SD = c(sd_R2, sd_RMSE, sd_bias, sd_RPD, sd_RPIQ, sd_PICP))

# Créer un data frame avec les résultats
resultsstatsTEST <- data.frame(
  Metric = c("R2", "RMSE", "Bias", "RPD", "RPIQ", "PICP"),
  Mean = c(mean_R2T, mean_RMSET, mean_biasT, mean_RPDT, mean_RPIQT, mean_PICPT),
  SD = c(sd_R2T, sd_RMSET, sd_biasT, sd_RPDT, sd_RPIQT, sd_PICPT))

# Sauvegarder resultsstatsVAL en fichier CSV
write.csv(resultsstatsVAL, file = "resultsstatsVAL.csv", row.names = FALSE)

# Sauvegarder resultsstatsTEST en fichier CSV
write.csv(resultsstatsTEST, file = "resultsstatsTEST.csv", row.names = FALSE)


# CALCUL DES MOYENNES DES PREDICTIONS POUR CHAQUE PIXEL
mean_pred_raster05_QRF <- calc(stack05, fun = mean, na.rm = TRUE)
mean_pred_raster95_QRF <- calc(stack95, fun = mean, na.rm = TRUE)

# CALCUL DE L'INTERVALLE DE PREDICTION
pred_interval_raster_QRF <- mean_pred_raster95_QRF - mean_pred_raster05_QRF

# ENREGISTREMENT DES RASTERS
writeRaster(mean_pred_raster05_QRF, filename = paste0(pathResults, "QRF_", "pred_interval_05.tif"), format = "GTiff") 
writeRaster(mean_pred_raster95_QRF, filename = paste0(pathResults, "QRF_", "pred_interval_95.tif"), format = "GTiff")
writeRaster(pred_interval_raster_QRF, filename = paste0(pathResults, "QRF_", "pred_interval_width.tif"), format = "GTiff")

# CARTE DES MOYENNES DE PREDICTIOSN # 
mean_pred_raster_QRF <- calc(stackQRF, fun = mean, na.rm = TRUE)
writeRaster(mean_pred_raster_QRF, filename = paste0(pathResults, "QRF_", "moyenne.tif"), format = "GTiff") 

# CARTE DE ECART-TYPE # 
sd_pred_raster_QRF <- calc(stackQRF, fun = sd, na.rm = TRUE)
writeRaster(sd_pred_raster_QRF, filename = paste0(pathResults, "QRF_", "sd.tif"), format = "GTiff")

# CARTE DE LA VARIANCE #  
variance_argileQRF <- calc(stackQRF, var) 
writeRaster(variance_argileQRF, filename = paste0(pathResults, "QRF_", "variance.tif"), format = "GTiff") 

# CARTE DU COEFFICIENT DE VARIATION #
coefficient_variationQRF <- function(stackQRF) {
  cv <- sd(stackQRF) / mean(stackQRF) * 100
  return(cv)
}

cv_rasterQRF <- calc(stackQRF, coefficient_variationQRF) 
writeRaster(cv_rasterQRF, filename = paste0(pathResults, "QRF_","coeff_variation.tif"), format = "GTiff") 


# ENREGISTREMENT HEURE SYSTEME FIN EXECUTION # 
temps_fin <- Sys.time()

# CALCUL DE LA DIFFERENCE HEURE SYSTEME #
temps_ecoule <- temps_fin - temps_debut

# AFFICHAGE DU TEMPS  # 
temps_ecoule_en_minutes <- as.numeric(temps_ecoule, units = "mins")
print(paste("Temps écoulé:", round(temps_ecoule_en_minutes, 2), "minutes"))


################ END  ################ 
################ END  ################ 
################ END  ################ 
